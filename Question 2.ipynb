{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is well-known that ridge regression tends to give similar coefficient values to correlated variables, whereas lasso may give quite different coefficient values to correlated variables. We will now explore this property in a very simple setting. Assume n are the number of training samples, p the number of dimensions, x in the input and y the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Write out the ridge regression optimization problem in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the optimization function in the slide:\n",
    "\\begin{equation*}\n",
    "\\sum_{i=1}^N  \\left( y_i - \\beta_0 - \\sum_{j=1}^p \\beta_jx_{ij} \\right)^2 + \\lambda\\sum_{j=1}^p\\beta_j^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the optimization problem in the provided setting:\n",
    "\\begin{equation*}\n",
    "(y_1 - \\hat{\\beta}_1x_1 - \\hat{\\beta}_2x_1)^2 + (y_2 - \\hat{\\beta}_1x_2 - \\hat{\\beta}_2x_2)^2 + \\lambda(\\hat{\\beta}_1^2 + \\hat{\\beta}_2^2).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Argue that in this setting, the ridge coefficient estimates satisfy $\\beta_1 = \\beta_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimizing the problem, we need to take the derivatives of the above expression in respect with $\\beta_1 and   \\beta_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first take the derivative of the expression in respect with $\\beta_1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "x_1(y_1 - \\hat{\\beta}_1x_1 - \\hat{\\beta}_2x_1) + x_2(y_2 - \\hat{\\beta}_1x_2 - \\hat{\\beta}_2x_2) + \\lambda\\hat{\\beta}_1 = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, take the derivative of the expression in respect with $\\beta_2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "x_1(y_1 - \\hat{\\beta}_1x_1 - \\hat{\\beta}_2x_1) + x_2(y_2 - \\hat{\\beta}_1x_2 - \\hat{\\beta}_2x_2) + \\lambda\\hat{\\beta}_2 = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By substracting the above two equations, we can get:\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}_1 = \\hat{\\beta}_2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Write out the lasso optimization problem in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the optimization function in the slide:\n",
    "\\begin{equation*}\n",
    "\\sum_{i=1}^N  \\left( y_i - \\beta_0 - \\sum_{j=1}^p \\beta_jx_{ij} \\right)^2 + \\lambda\\sum_{j=1}^p\\mid{\\beta_j}\\mid\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the optimization problem in the provided setting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "(y_1 - \\hat{\\beta}_1x_1 - \\hat{\\beta}_2x_1)^2 + (y_2 - \\hat{\\beta}_1x_2 - \\hat{\\beta}_2x_2)^2 + \\lambda(\\mid\\hat{\\beta}_1\\mid + \\mid\\hat{\\beta}_2\\mid).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Argue that in this setting, the lasso coefficients $\\beta_1 \\space and \\space \\beta_2$ are not unique â€“ in other words, there are many possible solutions to the optimization problem. Describe these solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the other form of the Lasso function:\n",
    "\\begin{equation*}\n",
    "(y_1 - \\hat{\\beta}_1x_1 - \\hat{\\beta}_2x_1)^2 + (y_2 - \\hat{\\beta}_1x_2 - \\hat{\\beta}_2x_2)^2\\text{ subject to }|\\hat{\\beta}_1| + |\\hat{\\beta}_2|\\le s\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We then can use the given setting and make the equation be like this:\n",
    "\\begin{equation*}\n",
    "2[y_1 - (\\hat{\\beta}_1 + \\hat{\\beta}_2)x_1]^2\\ge 0.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get that the solutions of optimizing lasso is $|\\hat{\\beta}_1| + |\\hat{\\beta}_2| \\le s$, which is a bunch of solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
